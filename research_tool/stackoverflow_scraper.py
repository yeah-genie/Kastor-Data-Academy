"""
Stack Overflow Scraper
ë¯¼ì¤€ í˜ë¥´ì†Œë‚˜: ì´ˆë³´ì ì§ˆë¬¸ì—ì„œ pain points ì¶”ì¶œ
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import time
import os
import re

class StackOverflowScraper:
    def __init__(self):
        self.questions = []
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def search_questions(self, tag, keywords, max_results=50):
        """
        íƒœê·¸ì™€ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ ê²€ìƒ‰

        Args:
            tag: íƒœê·¸ (ì˜ˆ: 'python', 'pandas')
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ (ì˜ˆ: 'beginner', 'confused')
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        """
        print(f"\nğŸ” ê²€ìƒ‰: [{tag}] {keywords}")

        # Stack Overflow ê²€ìƒ‰ URL
        search_query = f"[{tag}] {keywords}"
        url = f"https://stackoverflow.com/search?q={search_query.replace(' ', '+')}"

        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')

            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            results = soup.find_all('div', class_='s-post-summary', limit=max_results)

            for result in results:
                try:
                    question_data = self._parse_question(result, tag, keywords)
                    if question_data:
                        self.questions.append(question_data)
                except Exception as e:
                    continue

            print(f"  âœ“ {len(results)}ê°œ ì§ˆë¬¸ ìˆ˜ì§‘")

        except requests.exceptions.RequestException as e:
            print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
        except Exception as e:
            print(f"  âŒ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")

        time.sleep(2)  # Rate limiting

    def _parse_question(self, result, tag, keywords):
        """ì§ˆë¬¸ ì •ë³´ íŒŒì‹±"""
        try:
            # ì œëª©
            title_elem = result.find('h3', class_='s-post-summary--content-title')
            if not title_elem:
                title_elem = result.find('a', class_='s-link')
            title = title_elem.get_text(strip=True) if title_elem else "N/A"

            # URL
            link_elem = result.find('a', class_='s-link')
            url = "https://stackoverflow.com" + link_elem['href'] if link_elem and 'href' in link_elem.attrs else "N/A"

            # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°
            excerpt_elem = result.find('div', class_='s-post-summary--content-excerpt')
            excerpt = excerpt_elem.get_text(strip=True) if excerpt_elem else ""

            # í†µê³„ (votes, answers, views)
            stats = result.find_all('span', class_='s-post-summary--stats-item-number')
            votes = stats[0].get_text(strip=True) if len(stats) > 0 else "0"
            answers = stats[1].get_text(strip=True) if len(stats) > 1 else "0"
            views = stats[2].get_text(strip=True) if len(stats) > 2 else "0"

            # íƒœê·¸ë“¤
            tags_elem = result.find_all('a', class_='post-tag')
            tags = [tag.get_text(strip=True) for tag in tags_elem]

            return {
                'search_tag': tag,
                'search_keywords': keywords,
                'title': title,
                'excerpt': excerpt,
                'url': url,
                'votes': votes,
                'answers': answers,
                'views': views,
                'tags': ', '.join(tags),
                'collected_at': datetime.now()
            }

        except Exception as e:
            return None

    def scrape_beginner_pain_points(self):
        """ì´ˆë³´ì pain points ê²€ìƒ‰"""
        print(f"\n{'='*60}")
        print(f"ğŸ“š Stack Overflow ì´ˆë³´ì Pain Points ìˆ˜ì§‘")
        print(f"{'='*60}")

        # ë¯¼ì¤€ í˜ë¥´ì†Œë‚˜ íƒ€ê²Ÿ ê²€ìƒ‰ì–´
        searches = [
            ('python', 'beginner confused'),
            ('python', 'too difficult'),
            ('python', 'dont understand'),
            ('pandas', 'beginner struggling'),
            ('pandas', 'confusing'),
            ('data-science', 'beginner help'),
            ('machine-learning', 'beginner tutorial'),
            ('numpy', 'beginner error'),
        ]

        for tag, keywords in searches:
            self.search_questions(tag, keywords, max_results=30)

        print(f"\n{'='*60}")
        print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(self.questions)}ê°œ ì§ˆë¬¸")
        print(f"{'='*60}\n")

    def to_dataframe(self):
        """DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not self.questions:
            return pd.DataFrame()

        df = pd.DataFrame(self.questions)

        # ì¤‘ë³µ ì œê±°
        original_count = len(df)
        df = df.drop_duplicates(subset=['url'])
        removed = original_count - len(df)

        print(f"ğŸ“Š ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {len(df)}ê°œ ê³ ìœ  ì§ˆë¬¸ (ì¤‘ë³µ {removed}ê°œ ì œê±°)")
        return df

    def save_data(self, filename_prefix='stackoverflow_painpoints'):
        """ë°ì´í„° ì €ì¥"""
        df = self.to_dataframe()

        if df.empty:
            print("âš  ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None, None

        os.makedirs('output', exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # CSV ì €ì¥
        csv_path = f"output/{filename_prefix}_{timestamp}.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        # Excel ì €ì¥
        excel_path = f"output/{filename_prefix}_{timestamp}.xlsx"
        df.to_excel(excel_path, index=False, engine='openpyxl')

        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
        print(f"  - CSV: {csv_path}")
        print(f"  - Excel: {excel_path}")

        return csv_path, excel_path


def main():
    """ì‹¤í–‰"""
    scraper = StackOverflowScraper()
    scraper.scrape_beginner_pain_points()

    csv_path, excel_path = scraper.save_data('minjun_stackoverflow')

    df = scraper.to_dataframe()
    if not df.empty:
        print(f"\nğŸ“ˆ ìˆ˜ì§‘ ê²°ê³¼:")
        print(f"  - ì´ ì§ˆë¬¸: {len(df)}ê°œ")
        print(f"  - í‰ê·  ì¡°íšŒìˆ˜: {df['views'].apply(lambda x: int(str(x).replace('k', '000').replace('m', '000000')) if str(x).replace('k', '').replace('m', '').isdigit() else 0).mean():.0f}")

    return df


if __name__ == "__main__":
    main()
