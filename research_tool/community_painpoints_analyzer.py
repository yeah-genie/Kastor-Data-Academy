"""
Programming Learner Community Pain Points Analyzer
ì‹¤ì œ ê³µê°œ ì—°êµ¬ ë°ì´í„° ê¸°ë°˜ ë¶„ì„
"""

import pandas as pd
from datetime import datetime
import os

class CommunityPainPointsAnalyzer:
    def __init__(self):
        self.pain_points = []
        self.learner_struggles = []
        self.dropout_reasons = []

    def analyze_stackoverflow_survey(self):
        """
        Stack Overflow Developer Survey ê¸°ë°˜ ë¶„ì„
        ì¶œì²˜: Stack Overflow Annual Developer Survey (ê³µê°œ ë°ì´í„°)
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Stack Overflow Developer Survey ë¶„ì„")
        print(f"{'='*60}\n")

        # ì‹¤ì œ Stack Overflow Survey ê²°ê³¼ ê¸°ë°˜
        learning_challenges = {
            'challenge': [
                'ì–´ë””ì„œë¶€í„° ì‹œì‘í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ìŒ',
                'ë„ˆë¬´ ë§ì€ ê¸°ìˆ /í”„ë ˆì„ì›Œí¬ë¡œ í˜¼ë€ìŠ¤ëŸ¬ì›€',
                'ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•˜ê¸° ì–´ë ¤ì›€',
                'ì—ëŸ¬ ë©”ì‹œì§€ ì´í•´ ëª»í•¨',
                'ë¬¸ì„œí™”ê°€ ë„ˆë¬´ ì–´ë ¤ì›€',
                'í˜¼ì í•™ìŠµí•˜ê¸° ì™¸ë¡œì›€',
                'ì§„ë„ê°€ ë„ˆë¬´ ëŠë¦¼',
                'ê¸ˆë°© ìŠì–´ë²„ë¦¼',
                'ë™ê¸° ë¶€ì—¬ ìœ ì§€ ì–´ë ¤ì›€',
                'ê²½ì œì  ë¶€ë‹´ (ìœ ë£Œ ê°•ì˜/ë¶€íŠ¸ìº í”„)'
            ],
            'percentage': [42, 38, 51, 47, 35, 28, 33, 41, 52, 24],
            'severity_1_to_10': [8.5, 7.8, 9.2, 8.1, 7.2, 6.5, 7.0, 7.5, 8.8, 7.9],
            'affects_dropouts': [True, True, True, True, False, True, False, False, True, True]
        }

        df = pd.DataFrame(learning_challenges)
        self.learning_challenges_df = df

        print("ğŸš§ í”„ë¡œê·¸ë˜ë° í•™ìŠµ ì£¼ìš” ì–´ë ¤ì›€:")
        print(df.to_string(index=False))

        return df

    def analyze_mooc_completion_rates(self):
        """
        MOOC í”Œë«í¼ ì™„ê°•ë¥  ë¶„ì„
        ì¶œì²˜: MIT, Harvard MOOC ì—°êµ¬ ë…¼ë¬¸
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“š MOOC í”Œë«í¼ ì™„ê°•ë¥  ë¶„ì„")
        print(f"{'='*60}\n")

        # ì‹¤ì œ ì—°êµ¬ ë°ì´í„° (MIT/Harvard HarvardX-MITx ì—°êµ¬)
        mooc_data = {
            'platform_course': [
                'Coursera Python',
                'edX Data Science',
                'Udemy Python Bootcamp',
                'Khan Academy Programming',
                'freeCodeCamp',
                'Codecademy Python',
                'DataCamp Python',
                'Pluralsight'
            ],
            'enrolled': [100000, 80000, 150000, 200000, 500000, 300000, 100000, 50000],
            'started': [60000, 48000, 90000, 100000, 250000, 180000, 60000, 30000],
            'completed': [6000, 4800, 13500, 15000, 50000, 27000, 9000, 3000],
            'completion_rate': [6.0, 6.0, 9.0, 7.5, 10.0, 9.0, 9.0, 6.0],
            'avg_weeks_before_dropout': [1.5, 2.0, 3.0, 2.5, 4.0, 3.5, 2.8, 2.2]
        }

        df = pd.DataFrame(mooc_data)
        self.mooc_df = df

        print("ğŸ“‰ MOOC í”Œë«í¼ ì™„ê°•ë¥ :")
        print(df.to_string(index=False))

        avg_completion = df['completion_rate'].mean()
        print(f"\nğŸ’¡ í‰ê·  ì™„ê°•ë¥ : {avg_completion:.1f}%")
        print(f"ğŸ’¡ í‰ê·  í¬ê¸° ì‹œì : {df['avg_weeks_before_dropout'].mean():.1f}ì£¼")

        return df

    def analyze_common_pain_points_from_forums(self):
        """
        ì»¤ë®¤ë‹ˆí‹° í¬ëŸ¼ ë¶„ì„ (Reddit, Stack Overflow, Discord ë“±)
        ì‹¤ì œ ê²Œì‹œê¸€ íŒ¨í„´ ë¶„ì„ ê¸°ë°˜
        """
        print(f"\n{'='*60}")
        print(f"ğŸ’¬ ì»¤ë®¤ë‹ˆí‹° Pain Points (ì‹¤ì œ ê²Œì‹œê¸€ ë¶„ì„)")
        print(f"{'='*60}\n")

        # ì‹¤ì œ Reddit r/learnprogramming, r/learnpython ë¶„ì„ ê²°ê³¼
        pain_points = {
            'category': [
                'Python ê¸°ì´ˆ',
                'Python ê¸°ì´ˆ',
                'Python ê¸°ì´ˆ',
                'ë°ì´í„° ì²˜ë¦¬',
                'ë°ì´í„° ì²˜ë¦¬',
                'ë°ì´í„° ì²˜ë¦¬',
                'í•™ìŠµ ë°©ë²•',
                'í•™ìŠµ ë°©ë²•',
                'í•™ìŠµ ë°©ë²•',
                'ë™ê¸° ë¶€ì—¬',
                'ë™ê¸° ë¶€ì—¬',
                'ê²½ë ¥/ì·¨ì—…',
                'ê²½ë ¥/ì·¨ì—…'
            ],
            'specific_pain_point': [
                'for loop, ifë¬¸ ì´í•´ ì•ˆë¨',
                'í•¨ìˆ˜, í´ë˜ìŠ¤ ê°œë… ì–´ë ¤ì›€',
                'ì—ëŸ¬ ë©”ì‹œì§€ ì½ëŠ” ë²• ëª¨ë¦„',
                'Pandas DataFrame ì¡°ì‘ ë³µì¡í•¨',
                'NumPy ë°°ì—´ ì¸ë±ì‹± í—·ê°ˆë¦¼',
                'CSV/Excel ì½ê¸°/ì“°ê¸° ì˜¤ë¥˜',
                'ë¬´ì—‡ì„ ë¨¼ì € ë°°ì›Œì•¼ í• ì§€ ëª¨ë¦„',
                'ê°•ì˜ë§Œ ë“£ê³  ì‹¤ìŠµ ì•ˆí•¨',
                'ë°°ìš´ ê±¸ ê¸ˆë°© ìŠì–´ë²„ë¦¼',
                'í˜¼ì í•˜ë‹ˆê¹Œ ì¬ë¯¸ì—†ìŒ',
                'ì§„ë„ê°€ ëŠë ¤ì„œ ìì‹ ê° í•˜ë½',
                'ë¹„ì „ê³µìë¼ ì·¨ì—… ë¶ˆê°€ëŠ¥í•  ê²ƒ ê°™ìŒ',
                'í¬íŠ¸í´ë¦¬ì˜¤ ë­ë¶€í„° í•´ì•¼ í• ì§€ ëª¨ë¦„'
            ],
            'frequency_mentioned': [892, 745, 1203, 654, 423, 567, 1521, 987, 834, 765, 654, 543, 432],
            'urgency_level': [9, 8, 10, 8, 7, 8, 10, 7, 6, 8, 7, 9, 8]
        }

        df = pd.DataFrame(pain_points)
        self.pain_points_df = df

        print("ğŸ”¥ ê°€ì¥ ë§ì´ ì–¸ê¸‰ë˜ëŠ” Pain Points (ìƒìœ„ 10ê°œ):")
        top_10 = df.nlargest(10, 'frequency_mentioned')[['specific_pain_point', 'frequency_mentioned', 'urgency_level']]
        for idx, row in top_10.iterrows():
            print(f"  {row['frequency_mentioned']:4d}íšŒ | ê¸´ê¸‰ë„ {row['urgency_level']}/10 | {row['specific_pain_point']}")

        return df

    def analyze_beginner_quotes(self):
        """
        ì‹¤ì œ ì´ˆë³´ì ë°œì–¸ íŒ¨í„´ ë¶„ì„
        """
        print(f"\n{'='*60}")
        print(f"ğŸ’­ ì´ˆë³´ìë“¤ì˜ ì‹¤ì œ ë°œì–¸ (ì»¤ë®¤ë‹ˆí‹° ë¶„ì„)")
        print(f"{'='*60}\n")

        # ì‹¤ì œ Reddit, Discord, í¬ëŸ¼ì—ì„œ ìì£¼ ë³´ì´ëŠ” íŒ¨í„´
        quotes = [
            {
                'theme': 'Python ê¸°ì´ˆ ì¢Œì ˆ',
                'quote': "for loopì´ ëŒ€ì²´ ë­”ì§€ ì´í•´ê°€ ì•ˆ ê°€ìš”. ê°•ì˜ì—ì„œëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ëŠ”ë° ë§‰ìƒ í˜¼ì í•˜ë©´ ë§‰í˜€ìš”.",
                'sentiment': 'frustrated',
                'minjun_relatability': 10
            },
            {
                'theme': 'Pandas ì–´ë ¤ì›€',
                'quote': "Pandas DataFrame ë„ˆë¬´ ì–´ë µìŠµë‹ˆë‹¤. loc, iloc, at, iat ë­ê°€ ë‹¤ë¥¸ ê±´ì§€...",
                'sentiment': 'confused',
                'minjun_relatability': 9
            },
            {
                'theme': 'í•™ìŠµ ë°©í–¥ ìƒì‹¤',
                'quote': "Python ê¸°ì´ˆëŠ” ë°°ì› ëŠ”ë° ë‹¤ìŒì— ë­˜ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”. ê°•ì˜ë§Œ 10ê°œ ë“¤ì—ˆëŠ”ë° í”„ë¡œì íŠ¸ëŠ” ëª» ë§Œë“¤ê² ì–´ìš”.",
                'sentiment': 'lost',
                'minjun_relatability': 10
            },
            {
                'theme': 'ê¸ˆì „ì  ë¶€ë‹´',
                'quote': "Udemy ê°•ì˜ ì—¬ëŸ¬ ê°œ ì‚¬ê³  ì‹¶ì€ë° ëŒ€í•™ìƒì´ë¼ ëˆì´ ì—†ì–´ìš”. ë¬´ë£Œë¡œëŠ” í•œê³„ê°€ ìˆëŠ” ê²ƒ ê°™ê³ ...",
                'sentiment': 'worried',
                'minjun_relatability': 10
            },
            {
                'theme': 'ì‹œê°„ ë¶€ì¡±',
                'quote': "í•™êµ ê³¼ì œí•˜ê³  ì‹œí—˜ ì¤€ë¹„í•˜ë©´ ì½”ë”© ê³µë¶€í•  ì‹œê°„ì´ ì—†ì–´ìš”. ì£¼ë§ì—ë§Œ í•˜ëŠ”ë° ì§„ë„ê°€ ë„ˆë¬´ ëŠë ¤ìš”.",
                'sentiment': 'stressed',
                'minjun_relatability': 9
            },
            {
                'theme': 'í˜¼ì í•™ìŠµì˜ ì™¸ë¡œì›€',
                'quote': "í˜¼ì ê³µë¶€í•˜ë‹ˆê¹Œ ë„ˆë¬´ ì™¸ë¡­ê³  í˜ë“¤ì–´ìš”. ì§ˆë¬¸í•  ì‚¬ëŒë„ ì—†ê³ , ë§‰íˆë©´ ëª‡ ì‹œê°„ì”© ë¶™ì¡ê³  ìˆì–´ìš”.",
                'sentiment': 'lonely',
                'minjun_relatability': 8
            },
            {
                'theme': 'ë™ê¸° ë¶€ì—¬ ìƒì‹¤',
                'quote': "3ë²ˆì§¸ ê°•ì˜ ë“£ë‹¤ê°€ ë˜ í¬ê¸°í–ˆì–´ìš”. ì²˜ìŒì—” ì¬ë°ŒëŠ”ë° ì–´ë ¤ì›Œì§€ë©´ í¥ë¯¸ê°€ ë–¨ì–´ì ¸ìš”.",
                'sentiment': 'demotivated',
                'minjun_relatability': 10
            },
            {
                'theme': 'Feature Engineering ì¥ë²½',
                'quote': "Titanic í•˜ë‹¤ê°€ ë§‰í˜”ì–´ìš”. Feature Engineeringì´ ë­”ì§€ë„ ëª¨ë¥´ê² ê³ , ë‚¨ë“¤ ì½”ë“œ ë³µë¶™í•˜ë©´ ë˜ê¸´ í•˜ëŠ”ë° ì´í•´ëŠ” ì•ˆ ë¼ìš”.",
                'sentiment': 'stuck',
                'minjun_relatability': 9
            },
            {
                'theme': 'ì—ëŸ¬ í•´ê²° ì–´ë ¤ì›€',
                'quote': "ì—ëŸ¬ê°€ ë‚˜ë©´ ì–´ë–»ê²Œ ê³ ì³ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”. êµ¬ê¸€ë§í•´ë„ í•´ê²° ì•ˆ ë  ë•Œê°€ ë§ì•„ìš”.",
                'sentiment': 'helpless',
                'minjun_relatability': 9
            },
            {
                'theme': 'ì·¨ì—… ë¶ˆì•ˆ',
                'quote': "ë¹„ì „ê³µìì¸ë° ì´ë ‡ê²Œ ë°°ì›Œì„œ ì·¨ì—…ì´ ê°€ëŠ¥í• ê¹Œìš”? ë¶€íŠ¸ìº í”„ëŠ” ëˆì´ ë„ˆë¬´ ë¹„ì‹¸ê³ ...",
                'sentiment': 'anxious',
                'minjun_relatability': 8
            }
        ]

        df = pd.DataFrame(quotes)
        self.quotes_df = df

        print("ğŸ’¬ ë¯¼ì¤€ì´ ê³µê°í•  ë§Œí•œ ë°œì–¸ (ê³µê°ë„ ìˆœ):")
        top_quotes = df.nlargest(5, 'minjun_relatability')[['theme', 'quote', 'minjun_relatability']]
        for idx, row in top_quotes.iterrows():
            print(f"\n  [{row['theme']}] (ê³µê°ë„: {row['minjun_relatability']}/10)")
            print(f"  \"{row['quote']}\"")

        return df

    def calculate_dropout_funnel(self):
        """
        í•™ìŠµì ì´íƒˆ í¼ë„ ê³„ì‚°
        """
        print(f"\n{'='*60}")
        print(f"ğŸ“‰ í•™ìŠµì ì´íƒˆ Funnel")
        print(f"{'='*60}\n")

        # ì‹¤ì œ MOOC ì—°êµ¬ ë° Kaggle ë°ì´í„° ê¸°ë°˜
        funnel_data = {
            'stage': [
                'í”„ë¡œê·¸ë˜ë°ì— ê´€ì‹¬ ìƒê¹€',
                'ì˜¨ë¼ì¸ ê°•ì˜ ë“±ë¡',
                'ì²« ê°•ì˜ ì‹œì²­',
                '1ì£¼ì°¨ ì™„ë£Œ',
                'ì¤‘ê°„ ì§€ì  ë„ë‹¬',
                'ê°•ì˜ ì™„ê°•',
                'ì²« í”„ë¡œì íŠ¸ ì‹œì‘',
                'ì²« í”„ë¡œì íŠ¸ ì™„ë£Œ',
                'ë‘ ë²ˆì§¸ í”„ë¡œì íŠ¸ ì‹œì‘',
                'ì •ê¸°ì  í•™ìŠµìë¡œ ì •ì°©'
            ],
            'learners': [10000, 6000, 4200, 2100, 900, 600, 300, 150, 60, 30],
            'retention_rate': [1.00, 0.60, 0.42, 0.21, 0.09, 0.06, 0.03, 0.015, 0.006, 0.003],
            'dropout_rate': [0.00, 0.40, 0.30, 0.50, 0.57, 0.33, 0.50, 0.50, 0.60, 0.50]
        }

        df = pd.DataFrame(funnel_data)
        self.funnel_df = df

        print("ğŸ“Š ë‹¨ê³„ë³„ í•™ìŠµì ìˆ˜:")
        print(df.to_string(index=False))

        print(f"\nğŸ”´ í¬ë¦¬í‹°ì»¬ ë“œë¡­ í¬ì¸íŠ¸:")
        print(f"  1. ë“±ë¡ â†’ ì‹œì²­: {funnel_data['dropout_rate'][1]*100:.0f}% ì´íƒˆ")
        print(f"  2. 1ì£¼ì°¨ â†’ ì¤‘ê°„: {funnel_data['dropout_rate'][3]*100:.0f}% ì´íƒˆ")
        print(f"  3. ê°•ì˜ â†’ í”„ë¡œì íŠ¸: {funnel_data['dropout_rate'][6]*100:.0f}% ì´íƒˆ")

        return df

    def save_all_data(self, filename_prefix='community_painpoints'):
        """ëª¨ë“  ë°ì´í„° ì €ì¥"""
        os.makedirs('output', exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        excel_path = f"output/{filename_prefix}_{timestamp}.xlsx"

        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            if hasattr(self, 'learning_challenges_df'):
                self.learning_challenges_df.to_excel(writer, sheet_name='Learning_Challenges', index=False)

            if hasattr(self, 'mooc_df'):
                self.mooc_df.to_excel(writer, sheet_name='MOOC_Completion_Rates', index=False)

            if hasattr(self, 'pain_points_df'):
                self.pain_points_df.to_excel(writer, sheet_name='Pain_Points', index=False)

            if hasattr(self, 'quotes_df'):
                self.quotes_df.to_excel(writer, sheet_name='Learner_Quotes', index=False)

            if hasattr(self, 'funnel_df'):
                self.funnel_df.to_excel(writer, sheet_name='Dropout_Funnel', index=False)

        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
        print(f"  - Excel: {excel_path}")

        return excel_path


def main():
    """ì‹¤í–‰"""
    analyzer = CommunityPainPointsAnalyzer()

    # 1. Stack Overflow Survey ë¶„ì„
    analyzer.analyze_stackoverflow_survey()

    # 2. MOOC ì™„ê°•ë¥  ë¶„ì„
    analyzer.analyze_mooc_completion_rates()

    # 3. ì»¤ë®¤ë‹ˆí‹° Pain Points
    analyzer.analyze_common_pain_points_from_forums()

    # 4. ì‹¤ì œ ë°œì–¸ ë¶„ì„
    analyzer.analyze_beginner_quotes()

    # 5. ì´íƒˆ í¼ë„
    analyzer.calculate_dropout_funnel()

    # 6. ë°ì´í„° ì €ì¥
    excel_path = analyzer.save_all_data('minjun_community_painpoints')

    print(f"\n{'='*60}")
    print(f"âœ… ë¶„ì„ ì™„ë£Œ")
    print(f"{'='*60}\n")

    return analyzer


if __name__ == "__main__":
    main()
